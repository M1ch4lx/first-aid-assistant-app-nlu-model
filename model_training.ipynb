{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55a9b631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xd'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'xd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1bfa278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 00:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5179283.000000</td>\n",
       "      <td>6394387.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>634845.812500</td>\n",
       "      <td>77780.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2163.725600</td>\n",
       "      <td>43.342289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>0.520651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.658600</td>\n",
       "      <td>0.511659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.264100</td>\n",
       "      <td>0.156568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.211800</td>\n",
       "      <td>0.103197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>0.100062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>123.929700</td>\n",
       "      <td>0.037159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.038046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gotowy!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    MobileBertForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "# 1. Wczytanie i przygotowanie danych [cite: 87, 88]\n",
    "df = pd.read_csv(\"intents_examples.csv\")\n",
    "\n",
    "# Mapowanie etykiet tekstowych na liczbowe\n",
    "label_map = {\"REPEAT\": 0, \"NOT_BREATHING\": 1}\n",
    "df['label'] = df['intent'].map(label_map)\n",
    "\n",
    "# Podział na zbiór treningowy i testowy (np. 80/20) [cite: 88, 90]\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'].tolist(), \n",
    "    df['label'].tolist(), \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Tokenizacja [cite: 62]\n",
    "model_name = \"google/mobilebert-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_encodings = tokenize_function(train_texts)\n",
    "val_encodings = tokenize_function(val_texts)\n",
    "\n",
    "# 3. Tworzenie obiektu Dataset dla PyTorch\n",
    "class IntentDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = IntentDataset(train_encodings, train_labels)\n",
    "val_dataset = IntentDataset(val_encodings, val_labels)\n",
    "\n",
    "id2label = {0: \"REPEAT\", 1: \"NOT_BREATHING\"}\n",
    "label2id = {\"REPEAT\": 0, \"NOT_BREATHING\": 1}\n",
    "\n",
    "# 4. Inicjalizacja modelu MobileBERT [cite: 82]\n",
    "model = MobileBertForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=len(label_map),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# 5. Konfiguracja treningu [cite: 136]\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=10,              # Przy małym zbiorze 5 epok wystarczy\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=10,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=1,\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_strategy=\"epoch\",      # Ocena modelu po każdej epoce [cite: 137]\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=2e-5               # Mały LR zapobiega przeuczeniu\n",
    ")\n",
    "\n",
    "# 6. Uruchomienie Trenera\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# 7. Zapisanie modelu\n",
    "model.save_pretrained(\"./fine_tuned_mobilebert\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_mobilebert\")\n",
    "print(\"Model gotowy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aae711f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tekst: Możesz powtórzyć? -> Wynik: [{'label': 'REPEAT', 'score': 0.9993758797645569}]\n",
      "Tekst: On chyba nie oddycha! -> Wynik: [{'label': 'NOT_BREATHING', 'score': 0.9968045949935913}]\n",
      "Tekst: Jeszcze raz proszę -> Wynik: [{'label': 'REPEAT', 'score': 0.995864987373352}]\n",
      "Tekst: nie zrozumiałem -> Wynik: [{'label': 'REPEAT', 'score': 0.9993590712547302}]\n",
      "Tekst: nie rozumiem -> Wynik: [{'label': 'REPEAT', 'score': 0.5444620847702026}]\n",
      "Tekst: jeszcze raz -> Wynik: [{'label': 'REPEAT', 'score': 0.9967953562736511}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Załadowanie wytrenowanego modelu\n",
    "pipe = pipeline(\"text-classification\", model=\"./fine_tuned_mobilebert\", tokenizer=\"./fine_tuned_mobilebert\")\n",
    "\n",
    "# Testowe zdania\n",
    "test_sentences = [\n",
    "    \"Możesz powtórzyć?\",           # Powinno być REPEAT\n",
    "    \"On chyba nie oddycha!\",       # Powinno być NOT_BREATHING\n",
    "    \"Jeszcze raz proszę\",          # Powinno być REPEAT\n",
    "    \"nie zrozumiałem\",\n",
    "    \"nie rozumiem\",\n",
    "    \"jeszcze raz\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    result = pipe(sentence)\n",
    "    print(f\"Tekst: {sentence} -> Wynik: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0875c390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22759e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from setfit import SetFitModel, SetFitTrainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159c18b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wykryto 20 intencji.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "C:\\Users\\mkowa\\AppData\\Local\\Temp\\ipykernel_28976\\1451016425.py:51: DeprecationWarning: `SetFitTrainer` has been deprecated and will be removed in v2.0.0 of SetFit. Please use `Trainer` instead.\n",
      "  trainer = SetFitTrainer(\n",
      "Applying column mapping to the training dataset\n",
      "Applying column mapping to the evaluation dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57adba45b4f043278d143a9d84b1d2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 8760\n",
      "  Batch size = 16\n",
      "  Num epochs = 1\n",
      "c:\\Dev\\first-aid-assistant-app-nlu-model\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Memory.cpp:48.)\n",
      "  return data.pin_memory(device)\n",
      "c:\\Dev\\first-aid-assistant-app-nlu-model\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Memory.cpp:33.)\n",
      "  return data.pin_memory(device)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='548' max='548' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [548/548 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.164900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.064600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.042700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.039900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.026100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dev\\first-aid-assistant-app-nlu-model\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Memory.cpp:48.)\n",
      "  return data.pin_memory(device)\n",
      "c:\\Dev\\first-aid-assistant-app-nlu-model\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Memory.cpp:33.)\n",
      "  return data.pin_memory(device)\n",
      "***** Running evaluation *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ogólne Accuracy: 0.7455\n",
      "\n",
      "Szczegółowy raport klasyfikacji:\n",
      "------------------------------------------------------------\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "        ASSESS_BREATHING       0.50      0.67      0.57         3\n",
      "    ASSESS_CONSCIOUSNESS       1.00      1.00      1.00         3\n",
      "           ASSESS_SAFETY       1.00      1.00      1.00         2\n",
      "               CALL_HELP       1.00      1.00      1.00         2\n",
      "    DONT_KNOW_WHAT_TO_DO       1.00      1.00      1.00         3\n",
      "            LOCATION_AED       1.00      1.00      1.00         2\n",
      "PROCEDURE_CHOKING_ACTION       0.50      0.33      0.40         3\n",
      "           PROCEDURE_CPR       0.00      0.00      0.00         3\n",
      "     PROCEDURE_CPR_CHILD       1.00      0.50      0.67         2\n",
      "    PROCEDURE_HEMORRHAGE       1.00      0.33      0.50         3\n",
      "      PROCEDURE_RECOVERY       0.67      0.67      0.67         3\n",
      "            QUANTITY_ASK       0.50      1.00      0.67         3\n",
      "                  REPEAT       0.75      1.00      0.86         3\n",
      "       SITUATION_ALLERGY       1.00      0.33      0.50         3\n",
      "      SITUATION_BLEEDING       0.75      1.00      0.86         3\n",
      "          SITUATION_BURN       1.00      1.00      1.00         3\n",
      "       SITUATION_CHOKING       0.50      1.00      0.67         3\n",
      "   SITUATION_UNCONSCIOUS       1.00      0.67      0.80         3\n",
      "SITUATUION_NOT_BREATHING       0.75      1.00      0.86         3\n",
      "               WHAT_NEXT       1.00      0.50      0.67         2\n",
      "\n",
      "                accuracy                           0.75        55\n",
      "               macro avg       0.80      0.75      0.73        55\n",
      "            weighted avg       0.78      0.75      0.72        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import losses\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- FUNKCJA WCZYTUJĄCA YAML ---\n",
    "def load_nlu_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    \n",
    "    rows = []\n",
    "    for item in data['nlu']:\n",
    "        intent = item['intent']\n",
    "        examples = item['examples'].strip().split('\\n')\n",
    "        for ex in examples:\n",
    "            clean_text = re.sub(r'^-\\s*', '', ex).strip().strip('\"')\n",
    "            if clean_text:\n",
    "                rows.append({\"intent\": intent, \"text\": clean_text})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# 1. Wczytanie danych\n",
    "df = load_nlu_data(\"first-aid-assistant/nlu.yml\")\n",
    "\n",
    "# --- DYNAMICZNE TWORZENIE LABEL_MAP ---\n",
    "# Pobieramy unikalne intencje i przypisujemy im numery\n",
    "unique_intents = sorted(df['intent'].unique())\n",
    "label_map = {intent: i for i, intent in enumerate(unique_intents)}\n",
    "\n",
    "print(f\"Wykryto {len(label_map)} intencji.\")\n",
    "df['label'] = df['intent'].map(label_map)\n",
    "\n",
    "# Podział na zbiory (stratify zapewnia równe rozłożenie rzadkich intencji)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "# 2. Inicjalizacja modelu\n",
    "# labels_list musi być w kolejności indeksów (0, 1, 2...)\n",
    "labels_list = unique_intents \n",
    "\n",
    "model = SetFitModel.from_pretrained(\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    labels=labels_list\n",
    ")\n",
    "\n",
    "# 4. Inicjalizacja Trenera\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    loss_class=losses.CosineSimilarityLoss,\n",
    "    metric=\"accuracy\",\n",
    "    column_mapping={\"text\": \"text\", \"label\": \"label\"},\n",
    "    num_epochs=1,\n",
    "    batch_size=16,\n",
    "    use_amp=True\n",
    ")\n",
    "\n",
    "# 5. Trening\n",
    "trainer.train()\n",
    "\n",
    "# 6. Ewaluacja\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"\\nOgólne Accuracy: {metrics['accuracy']:.4f}\")\n",
    "\n",
    "y_true = test_df['intent'].values \n",
    "y_pred = model.predict(test_df['text'].tolist())\n",
    "\n",
    "print(\"\\nSzczegółowy raport klasyfikacji:\")\n",
    "print(\"-\" * 60)\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# 7. Zapisanie modelu\n",
    "model.save_pretrained(\"./setfit_intent_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04879058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', vocab_size=250002, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t250001: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import losses\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81fb7ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from './setfit_intent_model' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WYNIK      | PRZEWIDZIANA              | RZECZYWISTA               | PEWNOŚĆ\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "OK         | SITUATION_UNCONSCIOUS     | SITUATION_UNCONSCIOUS     | 97.84% | Znalazłem kogoś na chodniku, leży nieruchomo.\n",
      "OK         | SITUATION_UNCONSCIOUS     | SITUATION_UNCONSCIOUS     | 97.04% | Ta osoba leży na ziemii i nie ma z nią kontaktu.\n",
      "OK         | SITUATION_UNCONSCIOUS     | SITUATION_UNCONSCIOUS     | 88.67% | Chyba ktoś tu zemdlał, bo w ogóle nie reaguje.\n",
      "OK         | SITUATION_CHOKING         | SITUATION_CHOKING         | 77.93% | On się chyba poważnie zadławił jakimś kawałkiem.\n",
      "OK         | SITUATION_CHOKING         | SITUATION_CHOKING         | 91.00% | Pomocy, on dusi się i nie może złapać tchu!\n",
      "OK         | SITUATION_BLEEDING        | SITUATION_BLEEDING        | 98.84% | Z tej rany płynie bardzo duża ilość krwi.\n",
      "OK         | SITUATION_BLEEDING        | SITUATION_BLEEDING        | 97.75% | On ma krwotok z ramienia po wypadku.\n",
      "BŁĄD       | LOW_CONFIDENCE            | SITUATION_BLEEDING        | 27.18% | Rana jest głęboka i mocno przesiąka.\n",
      "OK         | SITUATION_BURN            | SITUATION_BURN            | 99.22% | Poparzył się mocno gorącą parą z rury.\n",
      "BŁĄD       | LOW_CONFIDENCE            | SITUATION_BURN            | 43.35% | On ma spaloną skórę na dłoni, co robić?\n",
      "OK         | SITUATION_BURN            | SITUATION_BURN            | 97.09% | Wylała na siebie wrzący płyn z garnka.\n",
      "OK         | SITUATION_ALLERGY         | SITUATION_ALLERGY         | 98.17% | Strasznie puchnie po użądleniu przez pszczołę.\n",
      "OK         | SITUATION_ALLERGY         | SITUATION_ALLERGY         | 96.08% | Zażył lekarstwo i pojawiła się pokrzywka na skórze.\n",
      "OK         | SITUATION_ALLERGY         | SITUATION_ALLERGY         | 78.26% | Dusi się po zjedzeniu potrawy, na którą jest uczulony.\n",
      "OK         | ASSESS_SAFETY             | ASSESS_SAFETY             | 86.22% | Czy okolica wokół nas jest teraz wolna od zagrożeń?\n",
      "OK         | ASSESS_SAFETY             | ASSESS_SAFETY             | 76.63% | Czy podejście do tego człowieka jest dla mnie bezpieczne?\n",
      "OK         | ASSESS_SAFETY             | ASSESS_SAFETY             | 96.58% | Jak upewnić się, że nic mi nie grozi podczas pomagania?\n",
      "OK         | ASSESS_CONSCIOUSNESS      | ASSESS_CONSCIOUSNESS      | 95.12% | Jak sprawdzić, czy ta osoba jest w ogóle świadoma?\n",
      "OK         | ASSESS_CONSCIOUSNESS      | ASSESS_CONSCIOUSNESS      | 91.06% | W jaki sposób wywołać jakąkolwiek reakcję u poszkodowanego?\n",
      "OK         | ASSESS_CONSCIOUSNESS      | ASSESS_CONSCIOUSNESS      | 58.90% | Co zrobić, żeby sprawdzić, czy on śpi, czy stracił przytomność?\n",
      "OK         | ASSESS_BREATHING          | ASSESS_BREATHING          | 95.13% | Nie jestem pewien, czy w ogóle czuję jego oddech.\n",
      "OK         | ASSESS_BREATHING          | ASSESS_BREATHING          | 96.38% | Jak prawidłowo odchylić żuchwę, żeby sprawdzić przepływ powietrza?\n",
      "OK         | ASSESS_BREATHING          | ASSESS_BREATHING          | 92.97% | W jakiej pozycji najlepiej sprawdzać, czy on oddycha?\n",
      "OK         | PROCEDURE_CPR             | PROCEDURE_CPR             | 65.04% | Pokaż mi krok po kroku jak robić RKO.\n",
      "BŁĄD       | QUANTITY_ASK              | PROCEDURE_CPR             | 99.00% | Z jaką dokładnie częstotliwością mam teraz uciskać?\n",
      "OK         | PROCEDURE_CPR             | PROCEDURE_CPR             | 97.84% | Jak prawidłowo robić masaż serca u dorosłej osoby?\n",
      "OK         | PROCEDURE_CPR_CHILD       | PROCEDURE_CPR_CHILD       | 97.32% | Moje niemowlę nagle przestało oddychać, co mam robić?\n",
      "OK         | PROCEDURE_CPR_CHILD       | PROCEDURE_CPR_CHILD       | 95.27% | Jak ratować takie malutkie dziecko w tej sytuacji?\n",
      "OK         | PROCEDURE_CPR_CHILD       | PROCEDURE_CPR_CHILD       | 93.69% | W którym dokładnie miejscu uciskać klatkę u niemowlaka?\n",
      "BŁĄD       | LOW_CONFIDENCE            | PROCEDURE_RECOVERY        | 30.83% | W którą stronę mam go teraz bezpiecznie obrócić?\n",
      "OK         | PROCEDURE_RECOVERY        | PROCEDURE_RECOVERY        | 80.15% | Jak dokładnie wygląda ułożenie nóg w pozycji bocznej?\n",
      "OK         | PROCEDURE_RECOVERY        | PROCEDURE_RECOVERY        | 65.30% | Pokaż jak go ustabilizować na boku, żeby się nie przekręcił.\n",
      "OK         | PROCEDURE_CHOKING_ACTION  | PROCEDURE_CHOKING_ACTION  | 79.37% | Jak wykonać te uderzenia w plecy, żeby były skuteczne?\n",
      "BŁĄD       | PROCEDURE_CPR             | PROCEDURE_CHOKING_ACTION  | 49.07% | Gdzie dokładnie przyłożyć splecione dłonie przy uciskaniu brzucha?\n",
      "BŁĄD       | PROCEDURE_CPR             | PROCEDURE_CHOKING_ACTION  | 81.90% | Pokaż mi technikę pomagania przy całkowitym zakrztuszeniu.\n",
      "OK         | PROCEDURE_HEMORRHAGE      | PROCEDURE_HEMORRHAGE      | 56.12% | Czym najlepiej zatamować ten tryskający krwotok?\n",
      "BŁĄD       | QUANTITY_ASK              | PROCEDURE_HEMORRHAGE      | 48.00% | Jak mocno muszę zacisnąć tę opaskę nad raną?\n",
      "BŁĄD       | LOW_CONFIDENCE            | PROCEDURE_HEMORRHAGE      | 34.58% | Co zrobić, jeśli pierwszy opatrunek jest cały czerwony od krwi?\n",
      "OK         | CALL_HELP                 | CALL_HELP                 | 96.51% | Proszę o natychmiastowe wezwanie ambulansu.\n",
      "BŁĄD       | LOW_CONFIDENCE            | CALL_HELP                 | 32.67% | Potrzebna jest karetka na cito pod ten adres.\n",
      "OK         | CALL_HELP                 | CALL_HELP                 | 96.36% | Wezwij profesjonalne służby ratunkowe.\n",
      "OK         | WHAT_NEXT                 | WHAT_NEXT                 | 91.49% | Co jest kolejnym punktem programu ratunkowego?\n",
      "OK         | WHAT_NEXT                 | WHAT_NEXT                 | 65.05% | Co mam zrobić zaraz po sprawdzeniu oddechu?\n",
      "OK         | WHAT_NEXT                 | WHAT_NEXT                 | 90.96% | Jaki jest dalszy krok?\n",
      "BŁĄD       | DONT_KNOW_WHAT_TO_DO      | REPEAT                    | 56.83% | Nie zrozumiałem do końca, co mam teraz zrobić.\n",
      "OK         | REPEAT                    | REPEAT                    | 98.57% | Mógłbyś powiedzieć to jeszcze raz, tylko wolniej?\n",
      "OK         | REPEAT                    | REPEAT                    | 95.58% | Powtórz ostatnią komendę, bo nie usłyszałem.\n",
      "OK         | QUANTITY_ASK              | QUANTITY_ASK              | 95.62% | Przez jaki czas mam kontynuować to chłodzenie?\n",
      "OK         | QUANTITY_ASK              | QUANTITY_ASK              | 95.18% | Ile dokładnie ma być tych uciśnięć w jednej serii?\n",
      "OK         | QUANTITY_ASK              | QUANTITY_ASK              | 98.92% | Ile sekund powinno trwać sprawdzanie tego oddechu?\n",
      "OK         | LOCATION_AED              | LOCATION_AED              | 93.50% | Skąd mam teraz wziąć defibrylator?\n",
      "OK         | LOCATION_AED              | LOCATION_AED              | 95.30% | Gdzie zazwyczaj w takich biurowcach montuje się urządzenia AED?\n",
      "OK         | LOCATION_AED              | LOCATION_AED              | 78.41% | W jakich miejscach publicznych szukać tego sprzętu?\n",
      "OK         | DONT_KNOW_WHAT_TO_DO      | DONT_KNOW_WHAT_TO_DO      | 99.01% | Jestem przerażony i nie wiem, od czego w ogóle zacząć.\n",
      "OK         | DONT_KNOW_WHAT_TO_DO      | DONT_KNOW_WHAT_TO_DO      | 92.73% | Zupełnie nie wiem, co robić, wszystko mi się miesza.\n",
      "OK         | DONT_KNOW_WHAT_TO_DO      | DONT_KNOW_WHAT_TO_DO      | 87.40% | Strasznie się boję, że mu zaszkodzę, pomóż mi.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Ogólna dokładność (z Threshold 45%): 82.14%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from setfit import SetFitModel\n",
    "\n",
    "# 1. Konfiguracja\n",
    "THRESHOLD = 0.45  # Jeśli pewność < 45%, bot prosi o doprecyzowanie\n",
    "MODEL_PATH = \"./setfit_intent_model\"\n",
    "TEST_FILE = \"intents_test.csv\"\n",
    "\n",
    "# 2. Załadowanie modelu i danych\n",
    "model = SetFitModel.from_pretrained(MODEL_PATH, fix_mistral_regex=True)\n",
    "test_df = pd.read_csv(TEST_FILE)\n",
    "\n",
    "test_sentences = test_df['text'].tolist()\n",
    "true_intents = test_df['intent'].tolist()\n",
    "\n",
    "# 3. Wykonanie predykcji\n",
    "probabilities = model.predict_proba(test_sentences)\n",
    "\n",
    "print(f\"{'WYNIK':<10} | {'PRZEWIDZIANA':<25} | {'RZECZYWISTA':<25} | {'PEWNOŚĆ'}\")\n",
    "print(\"-\" * 110)\n",
    "\n",
    "correct_count = 0\n",
    "\n",
    "for i, (sentence, true_label) in enumerate(zip(test_sentences, true_intents)):\n",
    "    # Pobranie najwyższego prawdopodobieństwa i odpowiadającej mu etykiety\n",
    "    probs = probabilities[i]\n",
    "    max_idx = probs.argmax().item()\n",
    "    score = probs[max_idx].item()\n",
    "    pred_label = model.labels[max_idx]\n",
    "    \n",
    "    # Logika Threshold - jeśli zbyt niska pewność, oznacz jako LOW_CONFIDENCE\n",
    "    final_label = pred_label if score >= THRESHOLD else \"LOW_CONFIDENCE\"\n",
    "    \n",
    "    # Sprawdzenie poprawności (czy przewidziana intencja zgadza się z plikiem testowym)\n",
    "    is_correct = (final_label == true_label)\n",
    "    status = \"OK\" if is_correct else \"BŁĄD\"\n",
    "    if is_correct: correct_count += 1\n",
    "    \n",
    "    # Wyświetlanie wyników z kolorem (opcjonalnie w terminalu)\n",
    "    print(f\"{status:<10} | {final_label:<25} | {true_label:<25} | {score:.2%} | {sentence}\")\n",
    "\n",
    "# 4. Podsumowanie statystyczne\n",
    "accuracy = (correct_count / len(test_df)) * 100\n",
    "print(\"-\" * 110)\n",
    "print(f\"Ogólna dokładność (z Threshold {THRESHOLD:.0%}): {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae01b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical_bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
